{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hand_on_2_AM_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOxcO2my67oS+19qD15HCLS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reis25/AprendizadoDeMquinas/blob/master/Hand_on_2_AM_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxxkkZhBBSvR",
        "colab_type": "text"
      },
      "source": [
        "Boa noite clã,\n",
        "\n",
        "Este é um tutorial basico de Machine Learning para iniciantes em LSTM. Você poderá aprender como implementar uma LSTM para o dataset seguindo o passo a passo do notebook. \n",
        "\n",
        "O dataset também pode ser encontrado no link: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzJiN_Yh5X6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c19043ef-267a-4dd5-8377-b18d39790a4a"
      },
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "\n",
        "numpy.random.seed(7)\n",
        "\n",
        "\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BQk3u17JNlA",
        "colab_type": "text"
      },
      "source": [
        "Depois de carregar o dataset, nós precisamos normalizar o número de palavras em uma comentário, afim de que todos os cometários possuam o mesmo tamanho para modelagem.\n",
        "\n",
        "O modelo ira aprender que valores que possuem 0 não devem influênciar em sua predição (pois não adicionam nenhuma informação).\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "Modelo possuindo sempre 5 entrada temos :\n",
        "\n",
        "(1,2,3,4,5) => (1,2,3,4,5)\n",
        "(1,2,5) => (1,2,5,0,0)\n",
        "(1) => (1,0,0,0,0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w70Xo9JECWE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fuAoeRgG70m",
        "colab_type": "text"
      },
      "source": [
        "Agora podemos definir, compilar e ajustar nosso modelo LSTM. \n",
        "\n",
        "* A primeira camada é a camada Embedded que usa 32 vetores de comprimento para representar cada palavra. \n",
        "\n",
        "* A próxima camada é a camada LSTM com 100 neurônios.\n",
        "\n",
        "* Finalmente, porque este é um problema de classificação, usamos uma camada Dense camada de saída com um único neurônio e,\n",
        " \n",
        "* uma função de ativação sigmóide para fazer previsões 0 ou 1 para as duas classes (boas e ruins) no problema.\n",
        "\n",
        "* Como é um problema de classificação binária, a função de loss é usada como a função binary-crossentrop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s8JiJ49CZbZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "a0521f29-0412-46e8-9156-59fef95019fc"
      },
      "source": [
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(100))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "\n",
        "# Avaliação final\n",
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 500, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "391/391 [==============================] - 223s 571ms/step - loss: 0.4884 - accuracy: 0.7615\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 223s 570ms/step - loss: 0.3208 - accuracy: 0.8694\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 224s 572ms/step - loss: 0.2676 - accuracy: 0.8952\n",
            "782/782 [==============================] - 71s 91ms/step - loss: 0.3857 - accuracy: 0.8377\n",
            "Accuracy: 83.77%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}